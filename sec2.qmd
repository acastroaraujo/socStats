---
title: "Data, sampling, and probability"
callout-appearance: simple
callout-icon: false
---

That time we learned a little bit about **probability** and **simulation**. This stuff is important, we can't really understand statistics without probability, as hinted at in @fig-prob-stats.

![Source: @wasserman2004](images/probability_statistics.png){#fig-prob-stats fig-align="center" width="100%"}

------------------------------------------------------------------------

To make this a little bit more concrete, here's a story about three coin flips:

::: {.callout-note style="text-align: center;"}
*Flip 3 fair coins and record the number of heads.*
:::

A **data generating process** (DGP) is just a simplified story about how data are produced and recorded, which we usually denote with some parameters. In this case we have the data $X$ (number of heads) and two parameters that control its *probability distribution*: $n = 3$ and $p = 0.5$.

This is how we write this same DGP in mathematical form:

$$
X \sim \text{Binomial}(n = 3, \ p = 0.5)
$$ {#eq-binomial-three-coins}

<aside>

**This notation *should* make sense eventually!**

</aside>

In R, we can simulate this process using the following function:

-   `rbinom(n, size, prob)`: draw `n` samples from the binomial distribution with some $n$ (`size`) and some $p$ (`prob`). Yes, this transition from $n$ to `size` is confusing!

    When $n = 1$ (or `size = 1`), we usually call this a "Bernoulli distribution."

    ```{r}
    ## 10 random draws from the DGP:
    rbinom(10, size = 3, prob = 1/2)
    ```

The **sample space** $\Omega$ for this three coin flip DGP---the set of all possible outcomes---is as follows:

$$
\Omega = 
\begin{Bmatrix}
HHH \\ HHT \\ HTT \\ TTT \\ TTH \\ THH \\ THT \\ HTH
\end{Bmatrix}
$$

<aside>

This sample space is a *set* has 8 outcomes.

</aside>

In this example we are recording the number of "heads." This is our random variable. A **random variable** $X$ *assigns* *some number to the underlying sample space.*

And so we have the following:

$$
\Omega = 
\begin{Bmatrix}
HHH \\ HHT \\ HTH \\ THH \\ TTH \\ THT \\ HTT \\ TTT
\end{Bmatrix}  \to
\begin{Bmatrix} 
3 \\ 2 \\ 2 \\ 2 \\ 1 \\ 1 \\ 1 \\ 0
\end{Bmatrix}
$$ {#eq-sample-space-three-coins}

Assigning a probability to these outcomes is relatively straightforward because the coin is fair ( $p = 0.5$ ), and so each of these outcomes is *equally likely*. Thus, the probability of each of the outcomes in $\Omega$ is $1/8$. Assigning probabilities get trickier when the coin is not fair, $p \neq 0.5$. *We will ignore this issue for now!*

Glaring intensely at @eq-sample-space-three-coins should convince you of the following statements:

$$
\begin{align}
\Pr(X = 3) &= 1/8, \\
\Pr(X = 2) &= 3/8, \\
\Pr(X = 1) &= 3/8, \\
\Pr(X = 0) &= 1/8
\end{align}
$$

This is exactly what the `dbinom()` does for us.

```{r}
X <- c(3, 2, 1, 0) ## number of heads
dbinom(X, size = 3, prob = 0.5)
```

*Note. Doing statistical inference simply means that we start with the recorded data and then ask questions about the potential DGPs, including the potential values of corresponding parameters!*
