[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Social Statistics I (Exercises)",
    "section": "",
    "text": "Preface\nSyllabus\nHi everyone, I will be uploading the homework questions to this website.\nFeel free to reach out to me with any questions."
  },
  {
    "objectID": "index.html#resources",
    "href": "index.html#resources",
    "title": "Social Statistics I (Exercises)",
    "section": "Resources",
    "text": "Resources\nThese are my personal recommendations for resources to start getting interested in statistics. It’s somewhat incomplete—e.g., there are no dedicated textbooks to causal inference, which is what we’ll cover next semester.\nClass Resources:\n\nR for Data Science (Wickham et al. 2023)\nI learned a lot using the first edition of this book. Feel free to skip some chapters on a first pass and come back to them if you think you might need them (e.g., strings, regular expressions, webscraping).\nAlso, I suggest you start with chapters 29 and 30.\nThe tidyverse style guide\nIt will help you write pretty code.\nData Visualization (Healy 2018)\nIt will help you make good graphs.\n\nGood books to play around with:\n\nData Analysis for Social Science: A Friendly and Practical Introduction (Llaudet and Imai 2022)\nVery introductory but useful.\nStatistical Inference via Data Science (Ismay and Kim 2019)\nIt’s good!\nQuantitative Social Science: An Introduction in Tidyverse (Imai and Williams 2022)\nI read this one a while ago, before it was re-written in tidyverse dialect. The chapters on probability and uncertainty are a great self-contained introduction to probability and statistical inference.\nRegression and Other Stories (Gelman et al. 2020)\nThis one seems a little too advanced for a first pass, but not advanced enough for a second pass? I like it a lot though.\n\nAdvanced Resources:\n\nAdvanced R (Wickham 2019).\nThis one is good for those of you that have a background in computer science and are looking for reasons to like R. It’s also good for those of you who finished (most of) R4DS and want to learn more general programming ideas.\nIntroduction to probability (Blitzstein and Hwang 2019)\nCovers more probability theory than what you’ll probably need, but it’s a fascinating topic and it’s very accessible.\nStatistical Rethinking (McElreath 2020)\nIt’s what the cool kids are into these days.\n\n\n\n\n\n\n\nBlitzstein, Joseph K., and Jessica Hwang. 2019. Introduction to Probability. CRC Press.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020. Regression and Other Stories. Cambridge University Press.\n\n\nHealy, Kieran. 2018. Data Visualization: A Practical Introduction.\n\n\nImai, Kosuke, and Nora Webb Williams. 2022. Quantitative Social Science: An Introduction in Tidyverse. Princeton University Press.\n\n\nIsmay, Chester, and Albert Y. Kim. 2019. Statistical Inference via Data Science: A ModernDive into r and the Tidyverse. CRC Press.\n\n\nLlaudet, Elena, and Kosuke Imai. 2022. Data Analysis for Social Science: A Friendly and Practical Introduction. Princeton University Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in r and Stan. CRC press.\n\n\nWickham, Hadley. 2019. Advanced R. CRC Press.\n\n\nWickham, Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. 2023. R for Data Science. \" O’Reilly Media, Inc.\"."
  },
  {
    "objectID": "sec1.html",
    "href": "sec1.html",
    "title": "Computing preliminaries",
    "section": "",
    "text": "That time we learned how to program in R, write simple reports using .qmd documents, and review some high school math."
  },
  {
    "objectID": "week1.html#data-structures",
    "href": "week1.html#data-structures",
    "title": "1  Week 1",
    "section": "1.1 Data Structures",
    "text": "1.1 Data Structures\n\n1.1.1 Vectors\nR has two kinds of vectors:\n\nAtomic vectors. All elements of the vector must have the same type (e.g., logical, integer, double, character).1 They are homogeneous.\nSee Figure 1.1.\nNote that integer and double are collectively known as numeric.\nLists. The elements of the vector can have different types. They can be heterogeneous.\n\nAll data structures—e.g., data frames, matrices, factors, dates, and more complex model objects—are built on top of these. All of these will have an additional class attribute. For example, a “data frame” (e.g., mtcars) is basically a list of atomic vectors that have the same length().\n\n\n\nFigure 1.1: Atomic vectors\nhttps://adv-r.hadley.nz/vectors-chap.html#atomic-vectors\n\n\n\n\n\n\n\n\nExercise 1.1\nTry typing typeof(mtcars) and class(mtcars) in the console to see what happens.\nNow type the following chunks of code into your console and understand what they do:\n\nnrow(mtcars)\nncol(mtcars)\nlength(mtcars)\ndim(mtcars)\nrownames(mtcars)\ncolnames(mtcars)\n\nBriefly describe what each of these do.\n\n\n\nNote. The absence of a vector is usually represented with NULL (as opposed to NA which is used to represent the absence of a value in a vector). NULL typically behaves like a vector of length 0.\nCreating vectors of length 1 (scalars).\nEach of the four primary types depicted in Figure 1.1 can be created using a special syntax:\n\nLogicals can be written in full (TRUE or FALSE), or abbreviated (T or F).\nDoubles are the default for numbers (123). They can also be specified in decimal (0.1234) and scientific (1.23e4).\nThere are three special values unique to doubles: Inf, -Inf, and NaN (not a number). Don’t worry about these for now!\nIntegers are written similarly to doubles but must be followed by L (1234L)\nStrings are surrounded by \" (\"hi\") or ' ('bye').\n\n\n\n\n\n\n\nExercise 1.2\nI suggest you always use long-form when creating logical vectors. Try assigning a different value to TRUE and to T.\n\n\nCode\nT &lt;- 123\nTRUE &lt;- 123\n\n\nWhat just happened?\nExercise 1.3\nImplicit coercion\nYou can create atomic vectors of any length with c() for “concatenate”.\nFor example:\n\n\nCode\nlgl &lt;- c(TRUE, FALSE, NA)\nint &lt;- c(1L, 6L, NA, 10L)\ndbl &lt;- c(1, NA, 2.5, 4.5)\nchr &lt;- c(NA, \"these are\", \"some strings\")\n\n\nRecall that atomic vectors are homogeneous. If you try to concatenate vectors of different types you will end up discovering implicit coercion. Basically, different types will be coerced in the following order: logical → integer → double → character.\nFor example, a logical and a character combine into a character:\n\n\nCode\nstr(c(TRUE, \"chr\")) ## str() is (almost) identical to dplyr::glimpse()\n\n\n chr [1:2] \"TRUE\" \"chr\"\n\n\nTest your knowledge of the vector coercion rules by predicting the output of the following uses of c():\n\n\nCode\nc(1, FALSE)\nc(\"a\", 1)\nc(TRUE, 1L)\n\n\nExercise 1.4\nExplicit coercion\nExplicit coercion happens when you call a function like as.logical(), as.integer(), as.double(), or as.character(). Use as.integer() on FALSE and TRUE, what values do they get coerced to?\nExercise 1.5\nThe most common form of implicit coercion\nThe following chunk of code creates a logical vector of size 75.\n\n\nCode\nx &lt;- sample(c(TRUE, FALSE), size = 75, replace = TRUE)\nstr(x)\n\n\n logi [1:75] FALSE FALSE FALSE TRUE FALSE TRUE ...\n\n\nUse sum(x) to get the number of TRUE values. Use mean(x) to get the proportion of TRUE values. Verify that mean(x) and sum(x) / length(x) give the same value.\n\n\n\nWe will usually use logical operators to transform a variable and then do the kinds of calculations in Exercise 1.5.\nFor example:\n\n\nCode\n## the proportion of cars in the dataset with more than 3 carburators\nmean(mtcars$carb &gt; 3)\n\n\n[1] 0.375\n\n\nSequences\nWe will sometimes create sequences of integers for various purposes (e.g., subsetting). For example, we can use the seq() to create a sequence of even numbers this way:\n\n\nCode\nseq(from = 2, to = 26, by = 2)\n\n\n [1]  2  4  6  8 10 12 14 16 18 20 22 24 26\n\n\nYou can create a simple sequence of numbers from x1 to x2 by using the : operator this way:\n\n\nCode\n1:10\n\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nCode\nseq(1, 10, by = 1)\n\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\n\n\n1.1.2 Subsetting\nVectors\nAs a reminder, you can subset named lists (and therefore data frames) with the $ operator.\nFor example:\n\n\nCode\nmtcars$mpg\n\n\n [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4\n[16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7\n[31] 15.0 21.4\n\n\nCode\nx &lt;- list(chr, lgl, letters)\nstr(x)\n\n\nList of 3\n $ : chr [1:3] NA \"these are\" \"some strings\"\n $ : logi [1:3] TRUE FALSE NA\n $ : chr [1:26] \"a\" \"b\" \"c\" \"d\" ...\n\n\nCode\nnames(x) &lt;- c(\"chr\", \"lgl\", \"alphabet\")\nstr(x)\n\n\nList of 3\n $ chr     : chr [1:3] NA \"these are\" \"some strings\"\n $ lgl     : logi [1:3] TRUE FALSE NA\n $ alphabet: chr [1:26] \"a\" \"b\" \"c\" \"d\" ...\n\n\nCode\nx$alphabet\n\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\n\nYou can also do this using the [ and [[ operators, but this time you have to put the name in quotation marks.\nThus:\n\n\nCode\nmtcars[[mpg]]\n\n\nError in (function(x, i, exact) if (is.matrix(i)) as.matrix(x)[[i]] else .subset2(x, : object 'mpg' not found\n\n\nCode\nmtcars[[\"mpg\"]]\n\n\n [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4\n[16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7\n[31] 15.0 21.4\n\n\n\n\n\n\n\n\nExercise 1.6\nWhat is the difference between mtcars[\"mpg\"] and mtcars[[\"mpg\"]]? More generally, what is the difference between the [ and [[ operators?\nWhich of the following two is TRUE?\n\n\nCode\nidentical(mtcars[\"mpg\"], mtcars$mpg)\nidentical(mtcars[[\"mpg\"]], mtcars$mpg)\n\n\n\n\n\nYou will be subsetting different kinds of things in R—mostly data frames—using integers and logicals.\n\n\n\n\n\n\nExercise 1.7\nletters is a built-in object in R that contains the 26 letters of English alphabet.\nUsing the [ operator, do the following:\n\nExtract the 17th value of letters\nCreate a sequence of even numbers from 2 to 26 and use that to subset letters\nUse 8:12 to subset letters.\n\nThis is known as integer subsetting.\nWhat happens if instead of [ you use [[?\n\n\n\nSubsetting + Assignment\nYou can use the assignment operator &lt;- in combination with subsetting to replace the values of a vector.\nFor example:\n\n\nCode\ndbl\n\n\n[1] 1.0  NA 2.5 4.5\n\n\nCode\ndbl[1] &lt;- 10\ndbl\n\n\n[1] 10.0   NA  2.5  4.5\n\n\nCode\ndbl[is.na(dbl)] &lt;- 0\ndbl\n\n\n[1] 10.0  0.0  2.5  4.5\n\n\nMake sure you understand what is.na() is doing here. Did we just do “integer” or “logical” subsetting?\n\n\n\n\n\n\nExercise 1.8\nNow that you know all this\nReplace the 18th value of letters with a missing value (NA).\n\n\n\n\n\n1.1.3 The most common error you’ll see\n\n\nCode\nmean[1:5]\n\n\nError in mean[1:5]: object of type 'closure' is not subsettable\n\n\nThis just means that you have tried to subset a function, and functions are most definitely not vectors.\nThis will happen for example if you think you created a dataset called df and try to extract a column:\n\n\nCode\ndf$col\n\n\nError in df$col: object of type 'closure' is not subsettable\n\n\n\n\n1.1.4 Data Frames\nThe most obvious use case $, [, or [[ is in the context of working with data frames.\nHere we will use the [ operator behaves differently when used on some objects—e.g., data frames and matrices.\n\nWhen subsetting with a single index, data frames behave like lists and index the columns, so mtcars[1:2] selects the first two columns.\nWhen subsetting with two indices, mtcars[1:3, ] selects the first three rows (and all the columns); mtcars[5, ] selects the fifth row and all columns; mtcars[1:5, \"cyl\"] selects the cyl column and the first five rows. Matrices behave in the same way.\n\nLogical subsetting\nThe most common way of using logicals to subset data frames is to learn some Boolean operators—e.g., &lt;, &lt;=, &gt;, &gt;=, !=, and ==.\nFor example, we can create a logical vector that tests for mtcars$wt values greater than 4.\n\n\nCode\nmtcars$wt &gt; 4\n\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE\n[13] FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n\n\nAnd then we can subset with [:\n\n\nCode\nmtcars[mtcars$wt &gt; 4, ]\n\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\n\n\n\n\n\n\n\n\nExercise 1.9\nSubset mtcars so that we only see the observations for which cyl == 4.\nSubset mtcars so that we only see the observations for which mpg is greater than 23.\n\n\n\nSometimes it will be easier to use the %in% operator to test for many conditions at the same time.\nFor example:\n\n\nCode\nmtcars[mtcars$carb %in% c(3, 6, 8), ]\n\n\n               mpg cyl  disp  hp drat   wt qsec vs am gear carb\nMerc 450SE    16.4   8 275.8 180 3.07 4.07 17.4  0  0    3    3\nMerc 450SL    17.3   8 275.8 180 3.07 3.73 17.6  0  0    3    3\nMerc 450SLC   15.2   8 275.8 180 3.07 3.78 18.0  0  0    3    3\nFerrari Dino  19.7   6 145.0 175 3.62 2.77 15.5  0  1    5    6\nMaserati Bora 15.0   8 301.0 335 3.54 3.57 14.6  0  1    5    8\n\n\nAlternatively we could have done this:\n\n\nCode\nmtcars[mtcars$carb == 3 | mtcars$carb == 6 | mtcars$carb == 8, ]\n\n\n               mpg cyl  disp  hp drat   wt qsec vs am gear carb\nMerc 450SE    16.4   8 275.8 180 3.07 4.07 17.4  0  0    3    3\nMerc 450SL    17.3   8 275.8 180 3.07 3.73 17.6  0  0    3    3\nMerc 450SLC   15.2   8 275.8 180 3.07 3.78 18.0  0  0    3    3\nFerrari Dino  19.7   6 145.0 175 3.62 2.77 15.5  0  1    5    6\nMaserati Bora 15.0   8 301.0 335 3.54 3.57 14.6  0  1    5    8\n\n\nWhich do you prefer?"
  },
  {
    "objectID": "week1.html#search",
    "href": "week1.html#search",
    "title": "1  Week 1",
    "section": "1.2 Search",
    "text": "1.2 Search\nIn this section I will introduce two functions that are pretty much useless except for the fact that they will help use understand how R finds “objects” in your R session: search() and find().\nType search() into your console. I you are like me—and haven’t loaded any package yet—you should see the exact same output as this:\n\n\nCode\nsearch()\n\n\n[1] \".GlobalEnv\"        \"package:stats\"     \"package:graphics\" \n[4] \"package:grDevices\" \"package:utils\"     \"package:datasets\" \n[7] \"package:methods\"   \"Autoloads\"         \"package:base\"     \n\n\n.GlobalEnv is the what’s known as the “global environment.” Any variable that shows up in your Environment pane is stored there.\nType names(.GlobalEnv) into the console and see what shows up. You’ll notice that there’s an object called .Random.seed in .GlobalEnv that doesn’t show up in your Environment pane. That’s because RStudio “hides” any variable that has a . prefix.\n\n\nCode\n.secret_var &lt;- 1:10\n.secret_var\n\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nYou should not be able to see .secret_var in the Environment pane and yet it’s there!\nAny time you type something in R, it will proceed to search for it sequentially: first, in .GlobalEnv, then in the built-in stats package, then in graphics, and so on until it reaches the base package.2\nSo, if you type asdfasdfasdf into the console, R will search all these environments and produce an error once it comes out empty handed.\n\n\nCode\nasdfasdfasdf\n\n\nError in eval(expr, envir, enclos): object 'asdfasdfasdf' not found\n\n\nBut if you type mtcars, R will search all these environments until it finds mtcars living in the built-in datasets package.\nYou can verify that this is the case using the find() function.\n\n\nCode\nfind(\"mtcars\")\n\n\n[1] \"package:datasets\"\n\n\nNow, suppose you decide to create an object called mtcars, which then gets saved to the global environment.\n\n\nCode\nmtcars &lt;- \"this is not the mtcars dataset\"\nmtcars\n\n\n[1] \"this is not the mtcars dataset\"\n\n\nIf you now type find(\"mtcars\") into the console you’ll see the names of two environments in the order that R searches for mtcars.\n\n\nCode\nfind(\"mtcars\")\n\n\n[1] \".GlobalEnv\"       \"package:datasets\"\n\n\nYou can still access the original mtcars dataset using the :: operator like this:\n\n\nCode\nstr(datasets::mtcars)\n\n\n'data.frame':   32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\n\n\nIn fact, you can use pkgname::obj to access any object in any package (even if you haven’t loaded it yet).\nFor example:\n\n\nCode\ndplyr::glimpse(datasets::mtcars)\n\n\nRows: 32\nColumns: 11\n$ mpg  &lt;dbl&gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,…\n$ cyl  &lt;dbl&gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8,…\n$ disp &lt;dbl&gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16…\n$ hp   &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180…\n$ drat &lt;dbl&gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,…\n$ wt   &lt;dbl&gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.…\n$ qsec &lt;dbl&gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18…\n$ vs   &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,…\n$ am   &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,…\n$ gear &lt;dbl&gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3,…\n$ carb &lt;dbl&gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2,…\n\n\n\n1.2.1 Errors!\nSuppose you want to analyze the penguins dataset contained in the palmerpenguins package.\nYou will have to type the following into your console once if you haven’t already:\n\n\nCode\ninstall.packages(\"palmerpenguins\")\n\n\nYou want to use the table() function to count up the number of times a specific year shows up in the dataset.\n\n\nCode\n# library(tidyverse)\n# library(palmerpenguins)\ntable(year)\n\n\nError in table(year): object 'year' not found\n\n\nOh no, an error!\nAfter realizing that you “commented out” the library(pkg) lines, you remove the # symbols and do this:\n\n\nCode\nlibrary(tidyverse)\nlibrary(palmerpenguins)\ntable(year)\n\n\nError in unique.default(x, nmax = nmax): unique() applies only to vectors\n\n\nOh no, a different error!\nYou realize that table() has no way of knowing that you wanted to access the year variable in the penguins dataset. You forgot to subset!\nThis should work:\n\n\nCode\ntable(penguins$year)\n\n\n\n2007 2008 2009 \n 110  114  120 \n\n\n\n\n\n\n\n\nExercise 1.10\nUsing what I told you earlier about the search() function, explain why you get two different errors. What is going on? What is R doing when you type table(year)? (You might want to type search() into the console again). In what package does R find the year object?"
  },
  {
    "objectID": "week1.html#dplyr-subsetting",
    "href": "week1.html#dplyr-subsetting",
    "title": "1  Week 1",
    "section": "1.3 dplyr subsetting",
    "text": "1.3 dplyr subsetting\nYou will almost never subset data frames in the way we did for the previous exercises. In fact, we won’t use “base R” much. Part of the reason we use tidyverse instead of base R is because the documentation for the tidyverse is excellent. Also, the error messages are easier to understand.\nWe will subset data frames using two functions contained in the dplyr package:\n\nslice() for integer subsetting.\nfilter() for logical subsetting.\n\n\nI recommend you follow these two links.\n\nDon’t forget to library(tidyverse) if you haven’t done so already.\n\n\nCode\nlibrary(tidyverse)\n\n\n\n\n\n\n\n\nExercise 1.11\nUse slice() to extract the even-numbered rows in the penguins dataset.\nIt will look something like this:\n\n\nCode\npenguins |&gt; \n  slice(\"SOME NUMERIC VECTOR GOES HERE\")\n\n\nNow use slice() to extract every third row—i.e., row 3, 6, 9, and so on.\nExercise 1.12\nUse filter() to extract the observations in the penguins dataset for which species == \"Gentoo\", island == \"Biscoe\", and body_mass_g is between 5,000 and 5,500."
  },
  {
    "objectID": "week1.html#footnotes",
    "href": "week1.html#footnotes",
    "title": "1  Week 1",
    "section": "",
    "text": "Technically, there are two other types of atomic vectors: complex and raw. I don’t think you’ll see much of these.↩︎\nIgnore “Autoloads” and “tools:rstudio” (this last one shows up when you type search() in the console if you are using RStudio). This is not important!↩︎"
  },
  {
    "objectID": "week2.html#communication",
    "href": "week2.html#communication",
    "title": "2  Week 2",
    "section": "2.1 Communication",
    "text": "2.1 Communication\nSkim Chapter 29 in R for Data Science (Wickham et al. 2023).1\nYou will then need to do the following:\n\nInstall Zotero in your computer if you haven’t already.\nRead Citations from Zotero and stop reading when you get to “Group Libraries.” This is 3 paragraphs.\nGo to this repository and download any CSL file you want—e.g., I am using the this one. Save the file in your Project folder.\nInstall the following packages:\n\n\nCode\ninstall.packages(\"modelsummary\")\ninstall.packages(\"flextable\")\ninstall.packages(\"tinytex\")\n\n\nYou should also type this into the console after installing tinytex:\n\n\nCode\ntinytex::install_tinytex()\n\n\n\n\n\n\n\n\n\nExercise\nDownload this .qmd file and put it into your project folder.\n\nChange Figure 1 (the cat picture) to an image of your liking. Adjust the caption accordingly.\nChange Equation 1 to a different equation.\nHint: If your not familiar with writing these sorts of equations, you can ask ChatGPT to generate the latex code for a different equation—e.g., “the normal distribution.”\nChange the “citations paragraph” at the end to so that it corresponds to yourself—i.e., different name, different citations.\nEdit the YAML file so that it includes your name (name), the appropriate date (date), a different font (mainfont), and whatever csl file you decided to go with (csl).\nToggle between the Source and Visual editors and try to understand what is going on.\nCreate a pdf and an html file.\nHint: This is how my .pdf and .html files look like.\nUpload the .qmd, .pdf, and .html files to your github repository."
  },
  {
    "objectID": "week2.html#data-wrangling",
    "href": "week2.html#data-wrangling",
    "title": "2  Week 2",
    "section": "2.2 Data Wrangling",
    "text": "2.2 Data Wrangling\n\n\n\n\n\n\nMultiple Exercises\nRead Chapter 4 of R4DS (Wickham et al. 2023) and complete the following exercises:\n\n4.2.5: all six exercises\n4.3.5: all seven exercises\n4.5.7: all six exercises\n\nAnswer these exercises in a quarto document and upload both .qmd and .html files to your github repository, just as you did for last week’s homework.\n\n\n\nYes, this means that for this week you will upload five different files to your github repository!\n\n\n\n\n\n\nWickham, Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. 2023. R for Data Science. \" O’Reilly Media, Inc.\"."
  },
  {
    "objectID": "week2.html#footnotes",
    "href": "week2.html#footnotes",
    "title": "2  Week 2",
    "section": "",
    "text": "Some additional resources to skim:\n\nhttps://quarto.org/docs/get-started/authoring/rstudio.html\nhttps://quarto.org/docs/visual-editor/technical.html\n\n↩︎"
  },
  {
    "objectID": "sec2.html",
    "href": "sec2.html",
    "title": "Data, sampling, and probability",
    "section": "",
    "text": "That time we learned a little bit about probability and simulation. This stuff is important, we can’t really understand statistics without probability, as hinted at in Figure 1.\n\n\n\nFigure 1: Source: Wasserman (2004)\n\n\n\n\n\n\n\n\nWasserman, Larry. 2004. All of Statistics: A Concise Course in Statistical Inference. Springer."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Blitzstein, Joseph K., and Jessica Hwang. 2019. Introduction to\nProbability. CRC Press.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020. Regression and\nOther Stories. Cambridge University Press.\n\n\nHealy, Kieran. 2018. Data\nVisualization: A Practical Introduction.\n\n\nImai, Kosuke, and Nora Webb Williams. 2022. Quantitative Social\nScience: An Introduction in Tidyverse. Princeton University Press.\n\n\nIsmay, Chester, and Albert Y. Kim. 2019. Statistical Inference via\nData Science: A ModernDive into r and the Tidyverse. CRC Press.\n\n\nLlaudet, Elena, and Kosuke Imai. 2022. Data Analysis for Social\nScience: A Friendly and Practical Introduction. Princeton\nUniversity Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course\nwith Examples in r and Stan. CRC press.\n\n\nWickham, Hadley. 2019. Advanced R. CRC Press.\n\n\nWickham, Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. 2023.\nR for Data Science. \" O’Reilly Media,\nInc.\"."
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "3  Week 3",
    "section": "",
    "text": "4 ggplot2\nDo the Steve Simulation, and then make them plot how the proportion of &gt; 0.5 changes with increases in n\n\\[\n\\frac{\\sigma}{\\sqrt{n}}\n\\]\nCode\nlibrary(tidyverse)\ntheme_set(theme_light(base_family = \"Optima\"))\n\nnum_sims &lt;- 500\npoll_size &lt;- 300\n\n(\nsims &lt;- tibble(sim_num = 1:num_sims) |&gt; \n    uncount(poll_size)\n  \n  \n  \n)"
  },
  {
    "objectID": "week3.html#ggplot2",
    "href": "week3.html#ggplot2",
    "title": "3  Week 3",
    "section": "3.1 ggplot2",
    "text": "3.1 ggplot2\n\n3.1.1 Introduction\nWe will look at the basic ggplot2 use using the faithful dataset, giving information on the eruption pattern of the Old Faithful geyser in Yellowstone National Park.\n\n\nCode\nlibrary(tidyverse)  ## ggplot2 is part of the tidyverse\ndata(\"faithful\")    ## this creates a copy of `faithful` in your global environment.\n\n# Basic scatterplot\nggplot(\n  data = faithful, \n  mapping = aes(x = eruptions, y = waiting)\n  ) + \n  geom_point()\n\n\n\n\n\nCode\n# Data and mapping can be given both as global (in ggplot()) or per layer\nggplot() + \n  geom_point(mapping = aes(x = eruptions, y = waiting), data = faithful)\n\n\n\n\n\nIf an aesthetic is linked to data it is put into aes()\n\n\nCode\nfaithful |&gt; \n  ggplot() + \n  geom_point(aes(x = eruptions, y = waiting, color = eruptions &lt; 3))\n\n\n\n\n\nIf you simple want to set it to a value, put it outside of aes()\n\n\nCode\nggplot(faithful) + \n  geom_point(aes(x = eruptions, y = waiting),\n             color = 'steelblue')\n\n\n\n\n\nSome geoms only need a single mapping and will calculate the rest for you—e.g., histograms and boxplots.\n\n\nCode\nggplot(faithful) + \n  geom_histogram(aes(x = eruptions))\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFinally, geoms are drawn in the order they are added. The point layer is thus drawn on top of the density contours in the example below:\n\n\nCode\nggplot(faithful, aes(x = eruptions, y = waiting)) + \n  geom_density_2d() + \n  geom_point()\n\n\n\n\n\n\n3.1.1.1 Exercise\n\n\n\n\n\n\nModify the code below to make the points larger squares and slightly transparent. See ?geom_point for more information on the point layer.\n\n\n\n\n\nCode\nggplot(faithful) + \n  geom_point(aes(x = eruptions, y = waiting))\n\n\n\n\n\n\n\n\nHint 1: transparency is controlled with alpha, and shape with shape\nHint 2: remember the difference between mapping and setting aesthetics\nHint 3: the shape argument can also be controlled via the following numeric values\n\n\n\n\n\nNote that shapes 21 to 25 can be assigned color (for the stroke) and fill values (shown above as pink).\n\n\n\n\n\n3.1.1.2 Exercise\n\n\n\n\n\n\nColor the two visible clusters in the histogram with different colors.\n\n\n\n\n\nCode\nggplot(faithful) + \n  geom_histogram(aes(x = eruptions))\n\n\n\n\n\n\n\n\nHint 1: For polygons you can map two different color-like aesthetics: color (the color of the stroke) and fill (the fill color)\n\n\n\n\n\n3.1.1.3 Exercise\n\n\n\n\n\n\nAdd a line that separates the two point distributions. See ?geom_abline for how to draw straight lines from a slope and intercept.\n\n\n\n\n\nCode\nggplot(faithful) + \n  geom_point(aes(x = eruptions, y = waiting))\n\n\n\n\n\n3.1.2 The “Statistics” Layer\nWe will use the mpg dataset giving information about fuel economy on different car models.\nEvery geom has a stat. This is why new data (count) can appear when using geom_bar().\n\n\nCode\ndata(\"mpg\")  ## this dataset lives in the ggplot2 package\n\nmpg |&gt; \n  ggplot(aes(x = class)) + \n  geom_bar()\n\n\n\n\n\nThe stat can be overwritten. If we have pre-computed count we don’t want any additional computations to perform and we use the identity stat to leave the data alone.\n\n\nCode\nmpg_counted &lt;- mpg |&gt; \n  group_by(class) |&gt; \n  summarize(count = n())\n  \nmpg_counted |&gt; \n  ggplot() + \n  geom_bar(aes(x = class, y = count), stat = 'identity')\n\n\n\n\n\nMost obvious “geom” + “stat” combinations have a dedicated geom constructor. For example, the one above is available directly as geom_col().\n\n\nCode\nggplot(mpg_counted) + ## `mpg_counted` is a summarized version of `mpg`\n  geom_col(aes(x = class, y = count))\n\n\n\n\n\n\n\n\n\n\n\nTypical geoms that rely heavily on “statistics layers” are geom_boxplot(), geom_density(), geom_smooth(), and geom_jitter().\n\n\n\nThis is the most confusing aspect about ggplot2. Thomas Pederson says we should think about it as a “data transformation” pipeline that sits in between the input data and the geom we want to use. Don’t worry about it for now! We will skip the exercises here!\n\n\n3.1.3 Scales\nScales define how the mapping you specify inside aes() should happen. All mappings have an associated scale even if not specified explicitly.\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy, color = class))\n\n\n\n\n\nWe can take control by adding one explicitly. All scales follow the same naming conventions—i.e., scale_&lt;aes&gt;_&lt;type&gt;.\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy, color = class)) + \n  scale_color_brewer(type = 'qual')\n\n\n\n\n\nPositional mappings (x and y) also have associated scales.\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) + \n  scale_x_continuous(breaks = c(3, 5, 6)) + \n  scale_y_log10()\n\n\n\n\n\n\n3.1.3.1 Exercise\n\n\n\n\n\n\nUse RColorBrewer::display.brewer.all() to see all the different palettes from Color Brewer and pick your favorite. Modify the code below to use it.\n\n\n\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy, color = class)) + \n  scale_color_brewer(type = 'qual')\n\n\n\n\n3.1.3.2 Exercise\n\n\n\n\n\n\nModify the code below to create a bubble chart (scatterplot with size mapped to a continuous variable) showing cyl with size. Make sure that only the present amount of cylinders (4, 5, 6, and 8) are present in the legend.\n\n\n\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy, color = class)) + \n  scale_color_brewer(type = 'qual')\n\n\n\n\n\n\n\n\nHint: The breaks argument in the scale is used to control which values are present in the legend.\n\n\n\n\n\n3.1.3.3 Exercise\n\n\n\n\n\n\nModify the code below so that color is no longer mapped to the discrete class variable, but to the continuous cty variable. What happens to the guide?\n\n\n\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy, color = class, size = cty))\n\n\n\n\n\n\n\n\nThe type of guide can be controlled with the guide argument in the scale, or with the guides() function. Continuous colors have a gradient color bar by default, but setting it to legend will turn it back to the standard look. What happens when multiple aesthetics are mapped to the same variable and uses the guide type?\n\n\n\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy, color = cty, size = cty))\n\n\n\n\n\n3.1.4 Facets\nThe facet defines how data is split among panels. The default facet (facet_null()) puts all the data in a single panel, while facet_wrap() and facet_grid() allows you to specify different types of small multiples.\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) + \n  facet_wrap(~ class)\n\n\n\n\n\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) + \n  facet_grid(year ~ drv)\n\n\n\n\n\n\n3.1.4.1 Exercise\n\n\n\n\n\n\nOne of the great things about facets is that they share the axes between the different panels. Sometimes this is undesirable though, and the behavior can be changed with the scales argument. Experiment with the different possible settings in the plot below:\n\n\n\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) + \n  facet_wrap(~ drv)\n\n\n\n\n\n3.1.5 Theme\nTheming defines the feel and look of your final visualization and is something you will normally defer to the final polishing of the plot. It is very easy to change looks with a pre-built theme\n\n\nCode\nggplot(mpg) + \n  geom_bar(aes(y = class)) + \n  facet_wrap(~year) + \n  theme_minimal()\n\n\n\n\n\nFurther adjustments can be done in the end to get exactly the look you want\n\n\nCode\nggplot(mpg) + \n  geom_bar(aes(y = class)) + \n  facet_wrap(~year) + \n  labs(title = \"Number of car models per class\",\n       caption = \"source: http://fueleconomy.gov\",\n       x = NULL,\n       y = NULL) +\n  scale_x_continuous(expand = c(0, NA)) + \n  theme_minimal() + \n  theme(\n    text = element_text('Avenir Next Condensed'),\n    strip.text = element_text(face = 'bold', hjust = 0),\n    plot.caption = element_text(face = 'italic'),\n    panel.grid.major = element_line('white', linewidth = 0.5),\n    panel.grid.minor = element_blank(),\n    panel.grid.major.y = element_blank(),\n    panel.ontop = TRUE\n  )\n\n\n\n\n\n\n3.1.5.1 Exercise\n\n\n\n\n\n\nThemes can be overwhelming, especially as you often try to optimize for beauty while you learn. To remove the last part of the equation, the exercise is to take the plot given below and make it as hideous as possible using the theme function. Go absolutely crazy, but take note of the effect as you change different settings.\n\n\n\n\n\nCode\nmpg |&gt; \n  ggplot(aes(y = class, fill = drv)) + \n  geom_bar() + \n  facet_wrap(~year) + \n  labs(\n    title = \"Number of car models per class\",\n    caption = \"source: http://fueleconomy.gov\",\n    x = 'Number of cars',\n    y = NULL\n  )"
  },
  {
    "objectID": "week3.html#simulation",
    "href": "week3.html#simulation",
    "title": "3  Week 3",
    "section": "3.2 Simulation",
    "text": "3.2 Simulation\n\n3.2.1 Voting Poll Example\nThere are many correct ways of simulating data.\nThis exercise takes off right were Steve left off (here). I have modified this code somewhat so that it’s easier to use for visualization—i.e., I created a function called simulation_votes(). We may eventually learn more of this, but for the moment let me explain how this function works.\nFirst, save the function to your global environment with the source() function.\n\n\nCode\nurl &lt;- \"https://raw.githubusercontent.com/acastroaraujo/socStats/main/simulation_function_week3.R\"\nsource(url)\n\n\nSecond, choose three parameters for the simulation:\n\ndem_prob_pop: the probability that the person will vote for “Democrats” in the population\nsample_size: the number of people in each “poll” (or sample)\nnum_sims: number of simulations\n\nThird, inspect the simulation data set.\n\n\nCode\nsims &lt;- simulation_votes(dem_prob_pop = 0.75, sample_size = 90, num_sims = 1e3)\nsims\n\n\n# A tibble: 90,000 × 5\n      id vote  dem_prob_pop sample_size num_sims\n   &lt;int&gt; &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;       &lt;chr&gt;   \n 1     1 Rep   0.75         90          1000    \n 2     1 Dem   0.75         90          1000    \n 3     1 Dem   0.75         90          1000    \n 4     1 Dem   0.75         90          1000    \n 5     1 Dem   0.75         90          1000    \n 6     1 Dem   0.75         90          1000    \n 7     1 Dem   0.75         90          1000    \n 8     1 Rep   0.75         90          1000    \n 9     1 Dem   0.75         90          1000    \n10     1 Dem   0.75         90          1000    \n# ℹ 89,990 more rows\n\n\nThe following chunk of code replicates what we did in class:\n\n\nCode\n## First I'll set up the ggplot2 theme I personally like best.\n## You might not have this font if you are on a Windows computer\ntheme_set(theme_light(base_family = \"Avenir Next Condensed\")) \n\nsims &lt;- simulation_votes(dem_prob_pop = 0.52, sample_size = 300, num_sims = 500)\n\nresults &lt;- sims |&gt; \n  group_by(id) |&gt; \n  summarize(dem_prop = mean(vote == \"Dem\"))\n\nresults\n\n\n# A tibble: 500 × 2\n      id dem_prop\n   &lt;int&gt;    &lt;dbl&gt;\n 1     1    0.507\n 2     2    0.533\n 3     3    0.49 \n 4     4    0.557\n 5     5    0.54 \n 6     6    0.49 \n 7     7    0.487\n 8     8    0.527\n 9     9    0.523\n10    10    0.547\n# ℹ 490 more rows\n\n\nCode\n# plot the results\n\nresults |&gt; \n  ggplot(aes(x = dem_prop)) +\n  geom_histogram(color = \"white\", boundary = .5, binwidth = .01) +\n  labs(title = \"Simulation\", subtitle = \"dem_prob = 0.52, sample_size = 300, num_sim = 500\")\n\n\n\n\n\nCode\n# how often does the poll predict the winner?\nmean(results$dem_prop &gt; 0.5)\n\n\n[1] 0.764\n\n\nCode\n# shade the same plot\nresults &lt;- results |&gt; \n  mutate(winner = if_else(dem_prop &gt; 0.5, \"Dem\", \"Rep\"))\n\nresults |&gt; \n  ggplot(aes(x = dem_prop, fill = winner)) +\n  geom_histogram(color = \"white\", boundary = .5, binwidth = .01) +\n  scale_fill_brewer(palette = \"Set1\", direction = -1)\n\n\n\n\n\nCode\n# strip plot\nresults |&gt; \n  ggplot(aes(dem_prop, \"\")) +\n  geom_boxplot(outlier.shape = NA) + \n  geom_jitter(height = 1/5, alpha = 0.2)\n\n\n\n\n\nCode\n# density plot\nresults |&gt; \n  ggplot(aes(dem_prop)) + \n  geom_density(fill = \"grey90\") + \n  geom_vline(xintercept = 0.5, linetype = \"dashed\")\n\n\n\n\n\n\n3.2.1.1 Exercise\n\n\n\n\n\n\nIn the simulation above, what is the average dem_prop? What is the standard deviation of dem_prop? How does this change for different values of sample_size?\n\n\n\n\n\n3.2.1.2 Exercise\n\n\n\n\n\n\nCreate five different simulations with different values of sample_size (e.g., 50, 200, 500, 1000, 2000). Put them together into a single dataset and then visualize the results using boxplots. What is going on?\n\n\n\n\n\n\n\n\n\nHint: You can stack together different datasets using the bind_rows() function in the dplyr package.\nHint: You will have to group_by(id, sample_size) to calculate dem_prop.\n\n\n\n\n\n3.2.1.3 Exercise\n\n\n\n\n\n\nCreate five different simulations with different values of dem_prob_pop (e.g., 0.49, 0.52, 0.55, 0.58). Put them together into a single dataset and then visualize the results using boxplots. What is going on?\n\n\n\n\n\n\n\n\n\nHealy, Kieran. 2018. Data Visualization: A Practical Introduction.\n\n\nWickham, Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. 2023. R for Data Science. \" O’Reilly Media, Inc.\"."
  },
  {
    "objectID": "week3.html#ggplot2-introduction",
    "href": "week3.html#ggplot2-introduction",
    "title": "3  Week 3",
    "section": "3.1 ggplot2 introduction",
    "text": "3.1 ggplot2 introduction\nWe will look at the basic ggplot2 use using the faithful dataset, giving information on the eruption pattern of the Old Faithful geyser in Yellowstone National Park.\n\n\nCode\nlibrary(tidyverse)  ## ggplot2 is part of the tidyverse\ndata(\"faithful\")    ## this creates a copy of `faithful` in your global environment.\n\n# Basic scatterplot\nggplot(\n  data = faithful, \n  mapping = aes(x = eruptions, y = waiting)\n  ) + \n  geom_point()\n\n\n\n\n\nCode\n# Data and mapping can be given both as global (in ggplot()) or per layer\nggplot() + \n  geom_point(mapping = aes(x = eruptions, y = waiting), data = faithful)\n\n\n\n\n\nIf an aesthetic is linked to data it is put into aes()\n\n\nCode\nfaithful |&gt; \n  ggplot() + \n  geom_point(aes(x = eruptions, y = waiting, color = eruptions &lt; 3))\n\n\n\n\n\nIf you simple want to set it to a value, put it outside of aes()\n\n\nCode\nggplot(faithful) + \n  geom_point(aes(x = eruptions, y = waiting),\n             color = 'steelblue')\n\n\n\n\n\nSome geoms only need a single mapping and will calculate the rest for you—e.g., histograms and boxplots.\n\n\nCode\nggplot(faithful) + \n  geom_histogram(aes(x = eruptions))\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFinally, geoms are drawn in the order they are added. The point layer is thus drawn on top of the density contours in the example below:\n\n\nCode\nggplot(faithful, aes(x = eruptions, y = waiting)) + \n  geom_density_2d() + \n  geom_point()\n\n\n\n\n\n\n3.1.1 Exercise\n\n\n\n\n\n\nModify the code below to make the points larger squares and slightly transparent. See ?geom_point for more information on the point layer.\n\n\n\n\n\nCode\nggplot(faithful) + \n  geom_point(aes(x = eruptions, y = waiting))\n\n\n\n\n\n\n\n\nHint 1: transparency is controlled with alpha, and shape with shape\nHint 2: remember the difference between mapping and setting aesthetics\nHint 3: shape can also be controlled via the following numeric values\nNote that shapes 21 to 25 can be assigned color (for the stroke) and fill values (above in pink).\n\n\n\n\n\n3.1.2 Exercise\n\n\n\n\n\n\nColor the two distributions in the histogram with different colors.\n\n\n\n\n\nCode\nggplot(faithful) + \n  geom_histogram(aes(x = eruptions))\n\n\n\n\n\n\n\n\nHint 1: For polygons you can map two different color-like aesthetics: color (the color of the stroke) and fill (the fill color)\n\n\n\n\n\n3.1.3 Exercise\n\n\n\n\n\n\nAdd a line that separates the two point distributions. See ?geom_abline for how to draw straight lines from a slope and intercept.\n\n\n\n\n\nCode\nggplot(faithful) + \n  geom_point(aes(x = eruptions, y = waiting))"
  },
  {
    "objectID": "week3.html#stat",
    "href": "week3.html#stat",
    "title": "3  Week 3",
    "section": "3.2 Stat",
    "text": "3.2 Stat\nWe will use the mpg dataset giving information about fuel economy on different car models.\nEvery geom has a stat. This is why new data (count) can appear when using geom_bar().\n\n\nCode\ndata(\"mpg\")\nggplot(mpg) + \n  geom_bar(aes(x = class))\n\n\nThe stat can be overwritten. If we have precomputed count we don’t want any additional computations to perform and we use the identity stat to leave the data alone\n\n\nCode\nlibrary(dplyr)\nmpg_counted &lt;- mpg %&gt;% \n  count(class, name = 'count')\nggplot(mpg_counted) + \n  geom_bar(aes(x = class, y = count), stat = 'identity')\n\n\nMost obvious geom+stat combinations have a dedicated geom constructor. The one above is available directly as geom_col()\n\n\nCode\nggplot(mpg_counted) + \n  geom_col(aes(x = class, y = count))\n\n\nValues calculated by the stat is available with the after_stat() function inside aes(). You can do all sorts of computations inside that.\n\n\nCode\nggplot(mpg) + \n  geom_bar(aes(x = class, y = after_stat(100 * count / sum(count))))\n\n\nMany stats provide multiple variations of the same calculation, and provides a default (here, density)\n\n\nCode\nggplot(mpg) + \n  geom_density(aes(x = hwy))\n\n\nWhile the others must be used with the after_stat() function\n\n\nCode\nggplot(mpg) + \n  geom_density(aes(x = hwy, y = after_stat(scaled)))\n\n\n\n3.2.0.1 Exercises\nWhile most people use geom_*() when adding layers, it is just as valid to add a stat_*() with an attached geom. Look at geom_bar() and figure out which stat it uses as default. Then modify the code to use the stat directly instead (i.e. adding stat_*() instead of geom_bar())\n\n\nCode\nggplot(mpg) + \n  geom_bar(aes(x = class))\n\n\n\nUse stat_summary() to add a red dot at the mean hwy for each group\n\n\nCode\nggplot(mpg) + \n  geom_jitter(aes(x = class, y = hwy), width = 0.2)\n\n\nHint: You will need to change the default geom of stat_summary()\n\n\n3.2.1 Scales\nScales define how the mapping you specify inside aes() should happen. All mappings have an associated scale even if not specified.\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy, color = class))\n\n\ntake control by adding one explicitly. All scales follow the same naming conventions.\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy, color = class)) + \n  scale_color_brewer(type = 'qual')\n\n\nPositional mappings (x and y) also have associated scales.\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) + \n  scale_x_continuous(breaks = c(3, 5, 6)) + \n  scale_y_continuous(trans = 'log10')\n\n\n\n3.2.1.1 Exercises\nUse RColorBrewer::display.brewer.all() to see all the different palettes from Color Brewer and pick your favourite. Modify the code below to use it\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy, color = class)) + \n  scale_color_brewer(type = 'qual')\n\n\n\nModify the code below to create a bubble chart (scatterplot with size mapped to a continuous variable) showing cyl with size. Make sure that only the present amount of cylinders (4, 5, 6, and 8) are present in the legend.\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy, color = class)) + \n  scale_color_brewer(type = 'qual')\n\n\nHint: The breaks argument in the scale is used to control which values are present in the legend.\nExplore the different types of size scales available in ggplot2. Is the default the most appropriate here?\n\nModify the code below so that color is no longer mapped to the discrete class variable, but to the continuous cty variable. What happens to the guide?\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy, color = class, size = cty))\n\n\n\nThe type of guide can be controlled with the guide argument in the scale, or with the guides() function. Continuous colors have a gradient color bar by default, but setting it to legend will turn it back to the standard look. What happens when multiple aesthetics are mapped to the same variable and uses the guide type?\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy, color = cty, size = cty))\n\n\n\n\n\n3.2.2 Facets\nThe facet defines how data is split among panels. The default facet (facet_null()) puts all the data in a single panel, while facet_wrap() and facet_grid() allows you to specify different types of small multiples\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) + \n  facet_wrap(~ class)\n\n\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) + \n  facet_grid(year ~ drv)\n\n\n\n3.2.2.1 Exercises\nOne of the great things about facets is that they share the axes between the different panels. Sometimes this is undiserable though, and the behaviour can be changed with the scales argument. Experiment with the different possible settings in the plot below:\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) + \n  facet_wrap(~ drv)\n\n\n\nUsually the space occupied by each panel is equal. This can create problems when different scales are used. Modify the code below so that the y scale differs between the panels in the plot. What happens?\n\n\nCode\nggplot(mpg) + \n  geom_bar(aes(y = manufacturer)) + \n  facet_grid(class ~ .)\n\n\nUse the space argument in facet_grid() to change the plot above so each bar has the same width again.\n\nFacets can be based on multiple variables by adding them together. Try to recreate the same panels present in the plot below by using facet_wrap()\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) + \n  facet_grid(year ~ drv)\n\n\n\n\n\n3.2.3 Coordinates\nThe coordinate system is the fabric you draw your layers on in the end. The default `coord_cartesion provides the standard rectangular x-y coordinate system. Changing the coordinate system can have dramatic effects\n\n\nCode\nggplot(mpg) + \n  geom_bar(aes(x = class)) + \n  coord_polar()\n\n\n\n\nCode\nggplot(mpg) + \n  geom_bar(aes(x = class)) + \n  coord_polar(theta = 'y') + \n  expand_limits(y = 70)\n\n\nYou can zoom both on the scale…\n\n\nCode\nggplot(mpg) + \n  geom_bar(aes(x = class)) + \n  scale_y_continuous(limits = c(0, 40))\n\n\nand in the coord. You usually want the latter as it avoids changing the plottet data\n\n\nCode\nggplot(mpg) + \n  geom_bar(aes(x = class)) + \n  coord_cartesian(ylim = c(0, 40))\n\n\n\n3.2.3.1 Exercises\nIn the same way as limits can be set in both the positional scale and the coord, so can transformations, using coord_trans(). Modify the code below to apply a log transformation to the y axis; first using scale_y_continuous(), and then using coord_trans(). Compare the results — how do they differ?\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = hwy, y = displ))\n\n\n\nCoordinate systems are particularly important in cartography. While we will not spend a lot of time with it in this workshop, spatial plotting is well supported in ggplot2 with geom_sf() and coord_sf() (which interfaces with the sf package). The code below produces a world map. Try changing the crs argument in coord_sf() to be '+proj=robin' (This means using the Robinson projection).\n\n\nCode\n# Get the borders of all countries\nworld &lt;- sf::st_as_sf(maps::map('world', plot = FALSE, fill = TRUE))\nworld &lt;- sf::st_wrap_dateline(world, \n                              options = c(\"WRAPDATELINE=YES\", \"DATELINEOFFSET=180\"),\n                              quiet = TRUE)\n# Plot code\nggplot(world) + \n  geom_sf() + \n  coord_sf(crs = \"+proj=moll\")\n\n\nMaps are a huge area in data visualisation and simply too big to cover in this workshop. If you want to explore further I advice you to explore the r-spatial wbsite as well as the website for the sf package\n\n\n\n3.2.4 Theme\nTheming defines the feel and look of your final visualisation and is something you will normally defer to the final polishing of the plot. It is very easy to change looks with a prebuild theme\n\n\nCode\nggplot(mpg) + \n  geom_bar(aes(y = class)) + \n  facet_wrap(~year) + \n  theme_minimal()\n\n\nFurther adjustments can be done in the end to get exactly the look you want\n\n\nCode\nggplot(mpg) + \n  geom_bar(aes(y = class)) + \n  facet_wrap(~year) + \n  labs(title = \"Number of car models per class\",\n       caption = \"source: http://fueleconomy.gov\",\n       x = NULL,\n       y = NULL) +\n  scale_x_continuous(expand = c(0, NA)) + \n  theme_minimal() + \n  theme(\n    text = element_text('Avenir Next Condensed'),\n    strip.text = element_text(face = 'bold', hjust = 0),\n    plot.caption = element_text(face = 'italic'),\n    panel.grid.major = element_line('white', size = 0.5),\n    panel.grid.minor = element_blank(),\n    panel.grid.major.y = element_blank(),\n    panel.ontop = TRUE\n  )\n\n\n\n3.2.4.1 Exercises\nThemes can be overwhelming, especially as you often try to optimise for beauty while you learn. To remove the last part of the equation, the exercise is to take the plot given below and make it as hideous as possible using the theme function. Go absolutely crazy, but take note of the effect as you change different settings.\n\n\nCode\nggplot(mpg) + \n  geom_bar(aes(y = class, fill = drv)) + \n  facet_wrap(~year) + \n  labs(title = \"Number of car models per class\",\n       caption = \"source: http://fueleconomy.gov\",\n       x = 'Number of cars',\n       y = NULL)"
  },
  {
    "objectID": "week3.html#statistics",
    "href": "week3.html#statistics",
    "title": "3  Week 3",
    "section": "4.2 Statistics",
    "text": "4.2 Statistics\nWe will use the mpg dataset giving information about fuel economy on different car models.\nEvery geom has a stat. This is why new data (count) can appear when using geom_bar().\n\n\nCode\ndata(\"mpg\")  ## this dataset lives in the ggplot2 package\n\nmpg |&gt; \n  ggplot(aes(x = class)) + \n  geom_bar()\n\n\nThe stat can be overwritten. If we have precomputed count we don’t want any additional computations to perform and we use the identity stat to leave the data alone\n\n\nCode\nmpg_counted &lt;- mpg |&gt; \n  group_by(class) |&gt; \n  summarize(count = n())\n  \nmpg_counted |&gt; \n  ggplot() + \n  geom_bar(aes(x = class, y = count), stat = 'identity')\n\n\nMost obvious “geom” + “stat” combinations have a dedicated geom constructor. For example, the one above is available directly as geom_col().\n\n\nCode\nggplot(mpg_counted) + \n  geom_col(aes(x = class, y = count))\n\n\n\n\n\n\n\n\nTypical geoms that rely heavily on “statistics layers” are geom_boxplot(), geom_density(), geom_smooth(), and geom_jitter().\n\n\n\nThis is the most confusing aspect about ggplot2. Thomas Pederson says we should think about it as a “data transformation” pipeline that sits in between the input data and the geom we want to use. Don’t worry about it for now! We will skip the exercises here!"
  },
  {
    "objectID": "week3.html#scales",
    "href": "week3.html#scales",
    "title": "3  Week 3",
    "section": "4.3 Scales",
    "text": "4.3 Scales\nScales define how the mapping you specify inside aes() should happen. All mappings have an associated scale even if not specified explicitly.\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy, color = class))\n\n\n\n\n\nWe can take control by adding one explicitly. All scales follow the same naming conventions—i.e., scale_&lt;aes&gt;_&lt;type&gt;.\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy, color = class)) + \n  scale_color_brewer(type = 'qual')\n\n\n\n\n\nPositional mappings (x and y) also have associated scales.\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) + \n  scale_x_continuous(breaks = c(3, 5, 6)) + \n  scale_y_log10()\n\n\n\n\n\n\n4.3.1 Exercise\n\n\n\n\n\n\nUse RColorBrewer::display.brewer.all() to see all the different palettes from Color Brewer and pick your favorite. Modify the code below to use it.\n\n\n\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy, color = class)) + \n  scale_color_brewer(type = 'qual')\n\n\n\n\n4.3.2 Exercise\n\n\n\n\n\n\nModify the code below to create a bubble chart (scatterplot with size mapped to a continuous variable) showing cyl with size. Make sure that only the present amount of cylinders (4, 5, 6, and 8) are present in the legend.\n\n\n\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy, color = class)) + \n  scale_color_brewer(type = 'qual')\n\n\n\n\n\n\n\n\nHint: The breaks argument in the scale is used to control which values are present in the legend.\n\n\n\n\n\n4.3.3 Exercise\n\n\n\n\n\n\nModify the code below so that color is no longer mapped to the discrete class variable, but to the continuous cty variable. What happens to the guide?\n\n\n\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy, color = class, size = cty))\n\n\n\n\n\n\n\n\nThe type of guide can be controlled with the guide argument in the scale, or with the guides() function. Continuous colors have a gradient color bar by default, but setting it to legend will turn it back to the standard look. What happens when multiple aesthetics are mapped to the same variable and uses the guide type?\n\n\n\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy, color = cty, size = cty))"
  },
  {
    "objectID": "week3.html#facets",
    "href": "week3.html#facets",
    "title": "3  Week 3",
    "section": "4.4 Facets",
    "text": "4.4 Facets\nThe facet defines how data is split among panels. The default facet (facet_null()) puts all the data in a single panel, while facet_wrap() and facet_grid() allows you to specify different types of small multiples.\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) + \n  facet_wrap(~ class)\n\n\n\n\n\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) + \n  facet_grid(year ~ drv)\n\n\n\n\n\n\n4.4.1 Exercise\n\n\n\n\n\n\nOne of the great things about facets is that they share the axes between the different panels. Sometimes this is undesirable though, and the behavior can be changed with the scales argument. Experiment with the different possible settings in the plot below:\n\n\n\n\n\nCode\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) + \n  facet_wrap(~ drv)"
  },
  {
    "objectID": "week3.html#theme",
    "href": "week3.html#theme",
    "title": "3  Week 3",
    "section": "4.5 Theme",
    "text": "4.5 Theme\nTheming defines the feel and look of your final visualization and is something you will normally defer to the final polishing of the plot. It is very easy to change looks with a pre-built theme\n\n\nCode\nggplot(mpg) + \n  geom_bar(aes(y = class)) + \n  facet_wrap(~year) + \n  theme_minimal()\n\n\n\n\n\nFurther adjustments can be done in the end to get exactly the look you want\n\n\nCode\nggplot(mpg) + \n  geom_bar(aes(y = class)) + \n  facet_wrap(~year) + \n  labs(title = \"Number of car models per class\",\n       caption = \"source: http://fueleconomy.gov\",\n       x = NULL,\n       y = NULL) +\n  scale_x_continuous(expand = c(0, NA)) + \n  theme_minimal() + \n  theme(\n    text = element_text('Avenir Next Condensed'),\n    strip.text = element_text(face = 'bold', hjust = 0),\n    plot.caption = element_text(face = 'italic'),\n    panel.grid.major = element_line('white', size = 0.5),\n    panel.grid.minor = element_blank(),\n    panel.grid.major.y = element_blank(),\n    panel.ontop = TRUE\n  )\n\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\n\n\n\n\n\n4.5.1 Exercise\nThemes can be overwhelming, especially as you often try to optimize for beauty while you learn. To remove the last part of the equation, the exercise is to take the plot given below and make it as hideous as possible using the theme function. Go absolutely crazy, but take note of the effect as you change different settings.\n\n\nCode\nmpg |&gt; \n  ggplot(aes(y = class, fill = drv)) + \n  geom_bar() + \n  facet_wrap(~year) + \n  labs(\n    title = \"Number of car models per class\",\n    caption = \"source: http://fueleconomy.gov\",\n    x = 'Number of cars',\n    y = NULL\n  )"
  },
  {
    "objectID": "week3.html#introduction",
    "href": "week3.html#introduction",
    "title": "3  Week 3",
    "section": "4.1 Introduction",
    "text": "4.1 Introduction\nWe will look at the basic ggplot2 use using the faithful dataset, giving information on the eruption pattern of the Old Faithful geyser in Yellowstone National Park.\n\n\nCode\nlibrary(tidyverse)  ## ggplot2 is part of the tidyverse\ndata(\"faithful\")    ## this creates a copy of `faithful` in your global environment.\n\n# Basic scatterplot\nggplot(\n  data = faithful, \n  mapping = aes(x = eruptions, y = waiting)\n  ) + \n  geom_point()\n\n\n\n\n\nCode\n# Data and mapping can be given both as global (in ggplot()) or per layer\nggplot() + \n  geom_point(mapping = aes(x = eruptions, y = waiting), data = faithful)\n\n\n\n\n\nIf an aesthetic is linked to data it is put into aes()\n\n\nCode\nfaithful |&gt; \n  ggplot() + \n  geom_point(aes(x = eruptions, y = waiting, color = eruptions &lt; 3))\n\n\n\n\n\nIf you simple want to set it to a value, put it outside of aes()\n\n\nCode\nggplot(faithful) + \n  geom_point(aes(x = eruptions, y = waiting),\n             color = 'steelblue')\n\n\n\n\n\nSome geoms only need a single mapping and will calculate the rest for you—e.g., histograms and boxplots.\n\n\nCode\nggplot(faithful) + \n  geom_histogram(aes(x = eruptions))\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFinally, geoms are drawn in the order they are added. The point layer is thus drawn on top of the density contours in the example below:\n\n\nCode\nggplot(faithful, aes(x = eruptions, y = waiting)) + \n  geom_density_2d() + \n  geom_point()\n\n\n\n\n\n\n4.1.1 Exercise\n\n\n\n\n\n\nModify the code below to make the points larger squares and slightly transparent. See ?geom_point for more information on the point layer.\n\n\n\n\n\nCode\nggplot(faithful) + \n  geom_point(aes(x = eruptions, y = waiting))\n\n\n\n\n\n\n\n\nHint 1: transparency is controlled with alpha, and shape with shape\nHint 2: remember the difference between mapping and setting aesthetics\nHint 3: shape can also be controlled via the following numeric values\nNote that shapes 21 to 25 can be assigned color (for the stroke) and fill values (above in pink).\n\n\n\n\n\n4.1.2 Exercise\n\n\n\n\n\n\nColor the two distributions in the histogram with different colors.\n\n\n\n\n\nCode\nggplot(faithful) + \n  geom_histogram(aes(x = eruptions))\n\n\n\n\n\n\n\n\nHint 1: For polygons you can map two different color-like aesthetics: color (the color of the stroke) and fill (the fill color)\n\n\n\n\n\n4.1.3 Exercise\n\n\n\n\n\n\nAdd a line that separates the two point distributions. See ?geom_abline for how to draw straight lines from a slope and intercept.\n\n\n\n\n\nCode\nggplot(faithful) + \n  geom_point(aes(x = eruptions, y = waiting))"
  },
  {
    "objectID": "week4.html#exercise",
    "href": "week4.html#exercise",
    "title": "4  Week 4",
    "section": "4.1 Exercise",
    "text": "4.1 Exercise\nSo far, we have generated data using the sample() and rbinom() functions. R has a built-in function for generating data from normal distributions, it’s called rnorm().\nRecall that all normal distributions exhibit the following behavior:\n\nThe probability that \\(x\\) is within one standard deviation \\(\\sigma\\) away from the mean is roughly 68%.\nThe probability that \\(x\\) is within two standard deviations \\(2\\sigma\\) away from the mean is roughly 95%.\nThe probability that \\(x\\) is above the mean ( \\(x \\geq \\mu\\) ) is 50%.\nThe probability that \\(x\\) is below the mean ( \\(x \\leq \\mu\\) ) is also 50%.\n\nThe following chunk generates 100,000 observations from a normal distribution with mean = 0 and standard deviation = 1.\n\n\nCode\nx &lt;- rnorm(100000, mean = 0, sd = 1)\n\n\n\n\n\n\n\n\nUse the mean() function to verify that x exhibits those four behaviors.\n\n\n\n\n\n\n\n\n\nHint: Remember that you can coerce numeric variables into TRUE and FALSE values using logical operators (==, &gt;, &lt;, etc.)"
  },
  {
    "objectID": "week4.html#exercise-1",
    "href": "week4.html#exercise-1",
    "title": "4  Week 4",
    "section": "4.2 Exercise",
    "text": "4.2 Exercise\n\n\n\n\n\n\nUse the quantile() function on the x created in the previous exercise. Explain the results."
  },
  {
    "objectID": "week4.html#exercise-2",
    "href": "week4.html#exercise-2",
    "title": "4  Week 4",
    "section": "4.3 Exercise",
    "text": "4.3 Exercise\n\n\n\n\n\n\nNow modify the probs argument in the quantile() to find the 0.5% and 99.5% percentiles of x.\n\n\n\n\n\n\n\n\n\nHint: If you Google “99 percent confidence interval” you should see a table that foreshadows the answer—i.e., you should get some number roughly equal to -2.576 and 2.576 respectively."
  },
  {
    "objectID": "week4.html#exercise-3",
    "href": "week4.html#exercise-3",
    "title": "4  Week 4",
    "section": "4.4 Exercise",
    "text": "4.4 Exercise\n\n\n\n\n\n\nUse the mean() function to verify that the probability of \\(x\\) being between \\(-2.576\\) and \\(2.576\\) is roughly 99%.\n\n\n\n\n\n\n\n\n\nHint: The logical operator for “AND” is &."
  },
  {
    "objectID": "week4.html#exercise-4",
    "href": "week4.html#exercise-4",
    "title": "4  Week 4",
    "section": "4.5 Exercise",
    "text": "4.5 Exercise\nCentral Limit Theorem\n\n\n\n\n\n\nLet \\(x = x_1 + \\dots + x_{20}\\), the sum of 20 independent uniform(0, 1) random variables. In R, create 1000 simulations of \\(x\\) and plot the histogram of their means.\n\n\n\n\n\n\n\n\n\nHint: You can simulate the sum of 20 independent uniform random variables using the following code:\n\n\nCode\nsum(runif(n = 20, min = 0, max = 1))\n\n\n[1] 8.089165\n\n\nThe simulation you create will have 1000 instances of a value like this.\n\n\n\nThe sampling distribution is the set of possible sample “statistics” (e.g., means) that could have been observed, if the data collection process had been repeated many many times. There’s an important theorem in statistics called the Central Limit Theorem (CLT) that proves that this sampling distribution converges to a normal distribution when the sample size is big enough, regardless of how our data looks like.\nThe standard error is how we estimate of the the standard deviation of the sampling distribution.\n\n\n\n\n\n\nUse the sd() function on the sampling distribution simulated earlier, then compare this value to the standard error given by \\(\\text{se}(x) = \\sigma_x / \\sqrt{N}\\) for one sample—i.e., sd(runif(20)) / sqrt(20). Do they match? Are they close?"
  },
  {
    "objectID": "week4.html#exercise-5",
    "href": "week4.html#exercise-5",
    "title": "4  Week 4",
    "section": "4.6 Exercise",
    "text": "4.6 Exercise\nSimulation study of CLT\nMany introductory statistics textbooks say that “sample sizes equal to or greater than 30 are often considered sufficient for the CLT to hold.”\n\n\n\n\n\n\nWrite down intuitively what you think this means.\n\n\n\nNow lets revisit last class’ simulation exercise.\nhttps://github.com/vaiseys/soc-stats-1/blob/main/demos/day-08.R\nYou’ll notice that the sample size is controlled by the following object:\n\n\nCode\nsvy_size &lt;- 2247  # number of people in each \"poll\"\n\n\nAnd the “true” population proportion is given by:\n\n\nCode\nest_prop &lt;- 1/3\n\n\nIn class, we also calculated the standard error “analytically” using the following mathematical equation:\n\\[\n\\text{se}_x = \\sqrt{\\frac{p (1-p)}{n}}\n\\]\nOr in code:\n\n\nCode\nstd_error &lt;- sqrt((1/3) * (2/3) / svy_size)\nstd_error\n\n\n[1] 0.009944712\n\n\nThis means that the 95% confidence interval should be roughly 2 standard errors away from 0.33\n\n\nCode\n0.33 - 1.96*std_error ## \"1.96\" is roughly \"2\"!\n\n\n[1] 0.3105084\n\n\nCode\n0.33 + 1.96*std_error\n\n\n[1] 0.3494916\n\n\nIn Steve’s simulation, this is given by ci95.\n\n\n\n\n\n\nRepeat Steve’s simulation with different values of svy_size. Is the 95% confidence interval still roughly 2 standard errors away from 0.33?\nDo these results change your initial interpretation of the idea that “sample sizes equal to or greater than 30 are often considered sufficient for the CLT to hold” ?"
  }
]